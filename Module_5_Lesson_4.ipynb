{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "from helper import l2_norm, poisson_2d_jacobi, poisson_solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters.\n",
    "nx = 101  # number of points in the x direction\n",
    "ny = 101  # number of points in the y direction\n",
    "xmin, xmax = 0.0, 1.0  # limits in the x direction\n",
    "ymin, ymax = -0.5, 0.5  # limits in the y direction\n",
    "Lx = xmax - xmin  # domain length in the x direction\n",
    "Ly = ymax - ymin  # domain length in the y direction\n",
    "dx = Lx / (nx - 1)  # grid spacing in the x direction\n",
    "dy = Ly / (ny - 1)  # grid spacing in the y direction\n",
    "\n",
    "# Create the gridline locations and the mesh grid.\n",
    "x = numpy.linspace(xmin, xmax, num=nx)\n",
    "y = numpy.linspace(ymin, ymax, num=ny)\n",
    "X, Y = numpy.meshgrid(x, y)\n",
    "\n",
    "# Create the source term.\n",
    "b = (-2 * (numpy.pi / 2)**2 *\n",
    "     numpy.sin(numpy.pi * X / Lx) *\n",
    "     numpy.cos(numpy.pi * Y / Ly))\n",
    "\n",
    "# Set the initial conditions.\n",
    "p0 = numpy.zeros((ny, nx))\n",
    "\n",
    "# Compute the analytical solution.\n",
    "p_exact = poisson_solution(x, y, Lx, Ly)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEEPEST DESCENT METHOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def poisson_2d_steepest_descent(p0, b, dx, dy, maxiter=20000, rtol=1e-6):\n",
    "    \n",
    "    def A(p):\n",
    "        # Apply the Laplacian operator to p.\n",
    "        return (-4.0 * p[1:-1, 1:-1] +\n",
    "                p[1:-1, :-2] + p[1:-1, 2:] +\n",
    "                p[:-2, 1:-1] + p[2:, 1:-1]) / dx**2\n",
    "    p = p0.copy()\n",
    "    rk = numpy.zeros_like(p)  # initial residual\n",
    "    Ar = numpy.zeros_like(p)  # to store the mat-vec multiplication\n",
    "    conv = []  # convergence history\n",
    "    diff = rtol + 1  # initial difference\n",
    "    ite = 0  # iteration index\n",
    "    while diff > rtol and ite < maxiter:\n",
    "        \n",
    "        #copy the previous solution\n",
    "        pk = p.copy()\n",
    "        \n",
    "        #compute residual rk\n",
    "        rk[1:-1, 1:-1] = b[1:-1, 1:-1] - A(pk)\n",
    "        \n",
    "        #compute the step size alpha\n",
    "        Ar[1:-1, 1:-1] = A(rk)\n",
    "        alpha = numpy.sum(rk * rk) / numpy.sum(rk * Ar)\n",
    "        \n",
    "        #update the solution\n",
    "        p = pk + alpha * rk\n",
    "        \n",
    "        #compute relative difference\n",
    "        diff = l2_norm(p, pk)\n",
    "        conv.append(diff)\n",
    "        \n",
    "        #increment the iteration index\n",
    "        ite += 1\n",
    "        \n",
    "    return p, ite, diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iterations = 2, diff = 1.3307695446303778e-16\n"
     ]
    }
   ],
   "source": [
    "# Compute the solution using the method of steepest descent.\n",
    "p, ites, diff = poisson_2d_steepest_descent(p0, b, dx, dy,\n",
    "                                               maxiter=20000,\n",
    "                                               rtol=1e-10)\n",
    "print(\"iterations = {}\".format(ites) + \", diff = {}\".format(diff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7499794373094477"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute the relative L2-norm of the error.\n",
    "l2_norm(p, p_exact)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONJUGATE GRADIENT METHOD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, the full set of steps for the method of conjugate gradients is:\n",
    "\n",
    "Calculate ${\\bf d}^0 = {\\bf r}^0$ (just  once), then\n",
    "\n",
    "1. Calculate $\\alpha = \\frac{{\\bf r}^k \\cdot {\\bf r}^k}{A{\\bf d}^k \\cdot {\\bf d}^k}$\n",
    "2. Update ${\\bf p}^{k+1}$\n",
    "3. Calculate ${\\bf r}^{k+1} = {\\bf r}^k - \\alpha A {\\bf d}^k$ $\\ \\ \\ \\ $(see <a href='#references'>Shewchuk (1994)</a>)\n",
    "4. Calculate $\\beta = \\frac{{\\bf r}^{k+1} \\cdot {\\bf r}^{k+1}}{{\\bf r}^k \\cdot {\\bf r}^k}$\n",
    "5. Calculate ${\\bf d}^{k+1}={\\bf r}^{k+1}+\\beta{\\bf d}^{k}$\n",
    "6. Repeat!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def poisson_2d_conjugate_gradient(p0, b, dx, dy, maxiter=20000, rtol=1e-6):\n",
    "    \n",
    "    def A(p):\n",
    "        # Apply the Laplacian operator to p.\n",
    "        return (-4.0 * p[1:-1, 1:-1] +\n",
    "                p[1:-1, :-2] + p[1:-1, 2:] +\n",
    "                p[:-2, 1:-1] + p[2:, 1:-1]) / dx**2\n",
    "    \n",
    "    p = p0.copy()\n",
    "    r = numpy.zeros_like(p)  # initial residual\n",
    "    Ad = numpy.zeros_like(p)  # to store the mat-vec multiplication\n",
    "    conv = []  # convergence history\n",
    "    diff = rtol + 1  # initial difference\n",
    "    ite = 0  # iteration index\n",
    "    \n",
    "    # Compute the initial residual.\n",
    "    r[1:-1, 1:-1] = b[1:-1, 1:-1] - A(p)\n",
    "    \n",
    "    # Set the initial search direction to be the residual.\n",
    "    d = r.copy()\n",
    "    \n",
    "    while diff > rtol and ite < maxiter:\n",
    "        \n",
    "        #copy the initial solution\n",
    "        pk = p.copy()\n",
    "        rk = r.copy()\n",
    "        \n",
    "        #compute the step size alpha\n",
    "        Ad[1:-1, 1:-1] = A(d)\n",
    "        alpha = numpy.sum(r * r) / numpy.sum(d * Ad)\n",
    "      \n",
    "        #update the solution\n",
    "        p = pk + alpha * d\n",
    "        r = rk - alpha * Ad\n",
    "       \n",
    "        #calculate beta parameter\n",
    "        beta = numpy.sum(r * r) / numpy.sum(rk * rk)\n",
    "        \n",
    "        #update the search direction vector d\n",
    "        d = r + beta * d\n",
    "        \n",
    "        #compute the difference\n",
    "        diff = l2_norm(p, pk)\n",
    "        conv.append(diff)\n",
    "        \n",
    "        #increment the iteration\n",
    "        ite += 1\n",
    "        \n",
    "    return p, ite, diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iterations = 2, diff = 1.2982770796281907e-16\n"
     ]
    }
   ],
   "source": [
    "# Compute the solution using the method of conjugate gradients.\n",
    "p, ites, diff = poisson_2d_conjugate_gradient(p0, b, dx, dy,\n",
    "                                                 maxiter=20000,\n",
    "                                                 rtol=1e-10)\n",
    "print(\"iterations = {}\".format(ites) + \", diff = {}\".format(diff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7499794373094477"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute the relative L2-norm of the error.\n",
    "l2_norm(p, p_exact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jacobi relaxation: 31227 iterations to reach a relative difference of 9.997923503623598e-11\n"
     ]
    }
   ],
   "source": [
    "# Compute the solution using Jacobi relaxation.\n",
    "p, ites, conv_jacobi = poisson_2d_jacobi(p0, b, dx, dy,\n",
    "                                         maxiter=40000,\n",
    "                                         rtol=1e-10)\n",
    "print('Jacobi relaxation: {} iterations '.format(ites) +\n",
    "      'to reach a relative difference of {}'.format(conv_jacobi[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MORE DIFFICULT POISSON PROBLEMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify the source term of the Poisson system.\n",
    "b2 = (numpy.sin(numpy.pi * X / Lx) *\n",
    "     numpy.cos(numpy.pi * Y / Ly) +\n",
    "     numpy.sin(6.0 * numpy.pi * X / Lx) *\n",
    "     numpy.sin(6.0 * numpy.pi * Y / Ly))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jacobi relaxation: 31226 iterations\n",
      "Method of steepest descent: 27059 iterations\n",
      "Method of conjugate gradients: 3 iterations\n"
     ]
    }
   ],
   "source": [
    "maxiter, rtol = 40000, 1e-10\n",
    "p, ites, conv = poisson_2d_jacobi(p0, b2, dx, dy,\n",
    "                                  maxiter=maxiter, rtol=rtol)\n",
    "print('Jacobi relaxation: {} iterations'.format(ites))\n",
    "p, ites, conv = poisson_2d_steepest_descent(p0, b2, dx, dy,\n",
    "                                            maxiter=maxiter,\n",
    "                                            rtol=rtol)\n",
    "print('Method of steepest descent: {} iterations'.format(ites))\n",
    "p, ites, conv = poisson_2d_conjugate_gradient(p0, b2, dx, dy,\n",
    "                                              maxiter=maxiter,\n",
    "                                              rtol=rtol)\n",
    "print('Method of conjugate gradients: {} iterations'.format(ites))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
